[
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Simon",
    "section": "",
    "text": "Simon Guest is a technical advisor who partners with educational organizations, helping them create exceptional software and hardware that reaches millions of students worldwide.\nWith extensive software engineering leadership experience at Code.org, Amazon, SAP, and Microsoft, Simon brings deep technical expertise to the intersection of education and technology. He is an active contributor to open-source education projects, articles, and books, a speaker at conferences, and regularly teaches at the K-12 and undergraduate level.\nBorn and raised in England, Simon has a HNC in Software Engineering from Plymouth College and a Master’s Degree in IT Security from the University of Westminster. He now lives in Kirkland, Washington, with his wife and their two sons."
  },
  {
    "objectID": "p/should-ctos-write-code/index.html",
    "href": "p/should-ctos-write-code/index.html",
    "title": "Should CTOs Write Code?",
    "section": "",
    "text": "Should CTOs - or VPs, Directors, Engineering Managers, or any other technical manager role - write code?\nIt’s a polarizing question. The answer often depends on your background, definition of what a CTO should do, and the size of your organization.\nIt’s a question I’ve struggled with for many years. I’ve regularly asked myself what, if any, code should I be writing? How can I add value without undermining the engineers on my team? And when I write code, why do I always feel guilty?"
  },
  {
    "objectID": "p/should-ctos-write-code/index.html#cons-of-writing-code-as-cto",
    "href": "p/should-ctos-write-code/index.html#cons-of-writing-code-as-cto",
    "title": "Should CTOs Write Code?",
    "section": "Cons of writing code as CTO",
    "text": "Cons of writing code as CTO\nNow, of course, writing code as CTO is a double-edged sword.\nOn one hand, my code may not be of the highest quality (even though secretly I refuse to believe it!) This can introduce a challenging power dynamic when I submit a pull request and other engineers need to provide critical feedback.\nIn addition, if my code is on the critical path, it has the potential to cause production issues. The team shouldn’t get paged in the middle of the night to resolve a bug that the CTO inadvertently checked in.\nFinally, it doesn’t scale. Locking myself in my office writing code takes me away from other tasks that help the organization more forward. In a former role as VP of Engineering, I was in the middle of a “personal project,” debugging a prototype, when one of my engineers came to me and said, “It’s great that you are working on that, but I really need you to do some ‘vp-ing’ right now.”\nSo, should CTOs write code? I was recently discussing this question with my coach, Jim Svagerko. He introduced me to a framework that introduces seven developmental action logics. I found this framework offered a new and interesting lens through which to answer the question."
  },
  {
    "objectID": "p/should-ctos-write-code/index.html#dont-be-the-expert",
    "href": "p/should-ctos-write-code/index.html#dont-be-the-expert",
    "title": "Should CTOs Write Code?",
    "section": "Don’t be the expert!",
    "text": "Don’t be the expert!\nAs I reflected more on this, I realized that whenever I’ve written code as an Expert, it has always backfired.\nAt Concur, we were developing our first set of partner integrations. I was new to my role and insisted that I jointly work with engineers to develop one of our connectors (even to the point of organizing a mini-hackathon!) Let’s just say the appetite for the project was low.\nAlso at Concur, I remember we were about to show our new expense product at our annual conference. While I was thrilled with the product, I couldn’t stand the “loading spinner” the team had copied and pasted from our previous product.\nThe team was running up against the deadline, so I wrote a new spinner and checked it in. While the demo looked smoother, I didn’t make many friends for bypassing the process (and they rightfully replaced it with a much better one when we got back.)\nFinally, at Code.org, I’ve been trying to migrate our development environment into containers. While it’s been intellectually rewarding, it’s been challenging to advocate this to other engineers - one reason being that I’m not in the position of having to use and maintain this every day.\nWhen I’ve written code while in the mode of an Expert action logic, I’ve often faced resistance. The code has not been adopted or it seems to have caused more downstream issues than the problems it was trying to solve.\nWhat’s the answer? Let’s revisit the action logic diagram:\n\n\n\nThe Action Logic Framework\n\n\nInstead of going from Achiever to Expert, when I think about contributing by writing code at CTO, I should instead look the other way - specifically to Strategist."
  },
  {
    "objectID": "p/should-ctos-write-code/index.html#writing-code-as-strategist",
    "href": "p/should-ctos-write-code/index.html#writing-code-as-strategist",
    "title": "Should CTOs Write Code?",
    "section": "Writing code as Strategist",
    "text": "Writing code as Strategist\nIn this action logic, the code that I write can set a vision. For example, “I had an idea how we can solve X. I’ve put together a quick prototype that shows the potential. What do you think?”\nWork aligned to this action logic is work that my engineers are not doing. It’s often exploring a future state or a lateral direction that’s not part of our defined roadmap.\nIn addition, the Strategist action logic produces code that is not on the critical path. Even if they adopt the approach, the team should take my prototype and rewrite it from scratch.\nThinking back, my most successful coding contributions have been when I’ve been operating in this Strategist action logic.\nAt Concur, I created a prototype of using GraphQL to serve travel requests. It was simple and used stubbed-out data, but it paved the way for a new set of APIs (which the team thankfully wrote from scratch.)\nAt Amazon, I prototyped a new technique for encrypting image data. It was well beyond the current product horizon, but helped with future planning cycles and eventually led to a patent.\nAnd at Code.org, I put together a quick prototype that showed how music could help teach computer science concepts. What started as a “I think there might be something here” has evolved into a wider pilot and a fully fledged activity we will launch later this year."
  },
  {
    "objectID": "p/writing-better-technical-documents/index.html",
    "href": "p/writing-better-technical-documents/index.html",
    "title": "Writing Better Technical Documents",
    "section": "",
    "text": "When I joined Code.org, several folks asked me what habits from Amazon I wanted to bring across with me. While Amazon has many peculiar qualities, the one I valued most was the culture of writing. As you’ve likely heard, Amazon values writing and using documents for decision making over creating slide decks.\nA good document makes meetings more efficient. Spending the first 10-15 minutes reading a well-written document gets everyone on the same page (both literally and figuratively) much quicker than any slide deck can. A good document also increases critical thinking skills. While it’s possible to “wing” a presentation by assembling a few bullet points the night before, the same isn’t true with a good document. You must instead invest the time exploring many angles of a topic before you can confidently put it into words.\nWriting, however, is hard. Coming from an engineering background, writing wasn’t (and still isn’t) as natural to me as other subjects. Over the past few years, I’ve found five techniques that help make for stronger technical documents. Here they are:\n\nTell a Story\nStorytelling isn’t just for works of fiction. A well-written technical document can still tell a story. The proposal for your next big idea can still have a protagonist, conflict, and a story-based narrative.\nWhen applying this to technical documents, I start by putting myself in the reader’s position. Who is the protagonist that I want to present to the reader? What is the issue or conflict? How will the protagonist resolve this? Many of the promotion documents I wrote at Amazon followed this idea. The protagonist was, of course, the individual being put up for promotion, and I shared the conflicts and issues they faced along the way (which later on became the justification for moving to the next level). While it wasn’t a novel, these story constructs helped create a compelling case.\nTwo books that have helped me learn more about storytelling are Story by Robert McKee and On Writing by Stephen King. While it’s in depth and aimed at screenwriters, McKee’s book provides the foundation for good storytelling. King’s memoir is a unique and engaging perspective on becoming a writer. While it’s geared more towards fiction writers, I found much of the content still applies to writing non-fiction work.\n\n\nMaintain a Consistent Style\nInconsistencies are easy to spot as a reader and notoriously difficult to see when you are writing. Yet, inconsistencies such as using 3rd Jan in one paragraph and 1/3 in the next will negatively affect how your document is received, even if the content is sound.\nDuring my time at Amazon, I created a style guide that I referred to when writing or reviewing documents. A style guide is just a set of rules to ensure consistency throughout a document. For example, my rule for dates is to use 3 Jan vs. 1/3 for days and Jan 2022 vs. 1/2022 for months. I have many other rules that include the use of numbers, spacing, acronyms, and so on.\nBuilding your own style guide is easy. I’d recommend starting with Elements of Style by William Strunk Jr. to learn about common patterns used in the publishing industry. As you get deeper into the subject, the Chicago Manual of Style by The University of Chicago Press Editorial Staff an invaluable resource for those documents that have to be perfect.\n\n\nStrive for Clarity\nWhen writing about a technical subject, it’s easy to use a style that biases towards overly complex jargon. The illusion is that doing so will make you sound much smarter, but quite the opposite is true. Instead of writing a document that your professor would be proud of, try writing in a style that a 10th grader could read. (Look for a tool that supports the Flesch Reading Ease score to determine how readable your own work is).\nOne habit that helps is writing in the active voice. It wasn’t until I took a writing class at Amazon that I discovered I was writing mostly in the passive voice (i.e., The code is optimized to be secure) vs. an active voice (i.e., I’ve optimized the code to be secure). I now use several tools (e.g., ProWritingAid) that prevent too many passive voice sentences creeping back in.\nOther books I would recommend include Sense of Style by Steven Pinker. Pinker covers an almost scientific approach for writing clearly and avoiding leaning too heavily towards an academic style. I also enjoyed On Writing Well by William Zinsser. One recommendation in Zinsser’s book is after you’ve completed your first draft, try to reduce the length of your prose by 50%. And once you’ve done that, try to reduce it again by another 50%. When I’ve used this approach with my own documents, it’s been a useful tool to distill down to the essence of what I’m wanting to say.\nUse Feedback Loops\nWriting is a journey of continual improvement and constructive feedback will help your documents become stronger.\nThere are many automated ways of generating feedback for your documents. I’ve had success with ProWritingAid as it integrates well with Google Docs, but most editors now support basic style and grammar checking.\nOnce you have addressed feedback using tools, ask other folks on your team to review your work, especially ahead of an important review. When they provide feedback, I recommend focusing on the areas they flag as confusing and think about how you can clarify these. Maybe it requires a stronger introduction or purpose? Maybe it’s the length of the paragraphs? Maybe you are using acronyms that the reader is less familiar with?\nIn addition, be a supportive reviewer for other writers on your team. At Amazon, when folks would send me documents to review, I would split my feedback into two parts: I’d cover the proposal (i.e., Let’s first discuss whether the idea makes sense) and then the writing style (i.e., I have some feedback on the grammar and structure of the document, if it is useful). On every occasion I shared feedback on the document’s style, it was well received.\n\n\nPractice Every Day\nEvery time you put hands to keyboard is an opportunity to become a better writer. Putting together a quick email? Maybe that’s a chance to check for passive voice. Composing a LinkedIn post? How could that be more concise? It may take longer to create and review that outgoing note, but doing so can help form natural habits that will make your writing stronger.\nFinally, besides practice, I’ve found that reading has made me a better writer. I always have a queue of books lined up, and even if they are on technical topics, it’s always fascinating to see how the author introduces the subject and keeps me, the reader, engaged."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html",
    "href": "p/creating-a-document-driven-culture/index.html",
    "title": "Creating a Document-Driven Culture",
    "section": "",
    "text": "When I was interviewing at Code.org, I asked whether there was a document-driven culture, one where well-written documents were the primary mechanism for driving decisions in the organization. The answer was a resounding yes!\nWhat I found is that like many other organizations, Code.org had a lot of documents, but they were often short and used for brainstorming. While these can be useful for generating ideas, based on my prior experience at Amazon, I advocated for a truly document-driven culture. While we still have work to do, adopting this culture is helping us increase the quality of our documents, explore ideas in more depth, and reach quicker decisions and outcomes.\nIn this document, I’ll share my experience of working in - and creating - a document-driven culture. This includes the advantages I see within my own teams and the elements of the writing and reading culture. I will conclude by exploring how your organization might benefit from embracing a document-driven culture and share the next steps for adopting this within your teams."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#deeper-thinking-ahead-of-proposing-ideas",
    "href": "p/creating-a-document-driven-culture/index.html#deeper-thinking-ahead-of-proposing-ideas",
    "title": "Creating a Document-Driven Culture",
    "section": "Deeper thinking ahead of proposing ideas",
    "text": "Deeper thinking ahead of proposing ideas\nWriting is hard. It’s more challenging to write a document than it is to put together bullet points. A well-written document can take days and weeks of preparation and requires you to think deeply about the topic. Putting an idea into words often requires you to explore different angles, resulting in a higher quality and well-tested idea.\nA document also forces you to challenge your own assumptions. There have been several occasions when I’ve started a document only to give up halfway - or pivot to a different proposal - as I realized my original idea wasn’t as good as I had initially thought."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#increased-employee-engagement-especially-in-a-remote-setting",
    "href": "p/creating-a-document-driven-culture/index.html#increased-employee-engagement-especially-in-a-remote-setting",
    "title": "Creating a Document-Driven Culture",
    "section": "Increased employee engagement, especially in a remote setting",
    "text": "Increased employee engagement, especially in a remote setting\nIn today’s Zoom-based culture, it’s challenging to maintain engagement, especially when presenting an idea. Many of us are guilty of half-listening to a presentation on Zoom, while keeping up with Slack and Email, only to return after the meeting with questions that were already covered.\nA document-driven culture is not just about writing documents, but also has strict rituals on how to read them in a group. These rituals can feel strange when you first try them, but they increase engagement and focus from every participant."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#getting-input-from-everyone-in-the-room",
    "href": "p/creating-a-document-driven-culture/index.html#getting-input-from-everyone-in-the-room",
    "title": "Creating a Document-Driven Culture",
    "section": "Getting input from everyone in the room",
    "text": "Getting input from everyone in the room\nA slide deck (or a conversation without a document) can create meetings with power dynamics. If, as a manager, I’m trying to communicate a change in direction via a presentation, my reports may be hesitant to speak up or challenge some of my assumptions - or be unaware at what point in the conversation they can interrupt.\nA document-driven culture eliminates this by providing structured opportunities where everyone, regardless of seniority or title, has ample time to ask questions and provide feedback on a document."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#resolute-decision-making",
    "href": "p/creating-a-document-driven-culture/index.html#resolute-decision-making",
    "title": "Creating a Document-Driven Culture",
    "section": "Resolute decision making",
    "text": "Resolute decision making\nIn many organizations, conversations around a new idea don’t reach a decision point until after several meetings. Often, in many of these meetings, we’ll also discover we need additional data which requires yet another meeting.\nA well-written document avoids this plethora of meetings by including all data, options, and recommendations, which reduces ambiguity and provides a clearer outcome."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#historical-knowledge-of-decisions",
    "href": "p/creating-a-document-driven-culture/index.html#historical-knowledge-of-decisions",
    "title": "Creating a Document-Driven Culture",
    "section": "Historical knowledge of decisions",
    "text": "Historical knowledge of decisions\nFinally, a document-driven culture leaves a paper trail for others to follow in the future, explaining the rationale behind a decision or other options that were considered.\nWithout a document, others, especially new employees, lack the context of the conversation and data, and end up relying on folklore to understand how decisions were made."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#opinionated-and-customer-focused-with-input-from-others",
    "href": "p/creating-a-document-driven-culture/index.html#opinionated-and-customer-focused-with-input-from-others",
    "title": "Creating a Document-Driven Culture",
    "section": "Opinionated and customer-focused, with input from others",
    "text": "Opinionated and customer-focused, with input from others\nRegardless of the document format and length, the strongest documents have three core elements:\nFirst, documents should be opinionated. You shouldn’t create a document that presents three options and ask for a discussion. Instead, create a document that presents three options together with a recommendation. The resulting discussion is more effective and becomes a yes/no decision on whether this is the right approach and how to move forward.\nAn opinionated document has a second side-effect of leaving a good paper trail. With an opinionated document, employees can go back and understand which options the team considered, the trade-offs, and the final recommendation.\nSecond, your documents should always link back to the customer, even if the customer is internal, such as another group in your organization. Many of the best documents I’ve read are the ones that intimately connect back to the benefits for the customer, even if the subject did not directly affect a consumer-facing product.\nFinally, documents should have relevant input from all stakeholders. You will be the primary author for your document, but it still needs to have input and ideas from others, especially if they will not be in the room for the review. I’ve often found this important for product proposals, where each document should have projected financial data provided ahead of time by the finance team."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#writing-style",
    "href": "p/creating-a-document-driven-culture/index.html#writing-style",
    "title": "Creating a Document-Driven Culture",
    "section": "Writing style",
    "text": "Writing style\nWriting style is very important. At Amazon, shortly after joining, I attended my first writing training, required for all new employees. A few years prior at Microsoft, I had been an editor-in-chief of a popular developer magazine, so I felt confident I knew how to write. The feedback I received from the training was, however, quite humbling.\nI discovered I wasn’t writing in the active voice, had many consistency errors, and the editor running the training returned my writing sample in a bloodbath of red ink, highlighting many more corrections.\nEven after Amazon, this remains an area I continue to develop. I’ve since found that creating and using my own style guide helps. A personal style guide acts as a set of rules and checklist, ensuring consistency throughout a document beyond what a spelling and grammar checker can provide."
  },
  {
    "objectID": "p/creating-a-document-driven-culture/index.html#getting-feedback",
    "href": "p/creating-a-document-driven-culture/index.html#getting-feedback",
    "title": "Creating a Document-Driven Culture",
    "section": "Getting feedback",
    "text": "Getting feedback\nFirst, the author should ask if there are high-level questions or comments about the document. This opens up for any general feedback, such as confirmation that other individuals outside of the review have also seen and contributed to the document. These high-level comments rarely get into a discussion about the idea, unless there is something obvious about the approach. For example, “Didn’t we try something similar three years ago?”\nAfter everyone has shared their overall comments, the author, now facilitator, invites feedback on a page-by-page basis. A good lead-in for this will be, “Are there any comments on page 1?” The group now reviews their notes, and the floor is open for discussion. In a setting with printed copies of the document, line numbers in the document help the reader precisely refer to part of the document. For example, “On line 24, you mention that you’ve seen increased bug reports. Do you have data that supports this?”\nOnce everyone has had an opportunity to provide feedback on page 1, the author/facilitator will move on to page 2, then page 3, and so on. For longer documents, there’s no need to review the appendices page-by-page. Once the group reaches the end of the document, the author asks for any final feedback before moving on to recommendations.\nAs the document was opinionated, the author should have everything they need to move forward. The outcome could be that the group agrees with the approach and wants to move forward. Alternatively, during the discussion, maybe the group preferred another option or a different approach. Finally, while it was rare, one outcome could be that the group felt they needed more information. Here, the group asks the author to update the document and set up additional time for a further review."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html",
    "href": "p/how-we-accrue-technical-debt/index.html",
    "title": "How We Accrue Technical Debt",
    "section": "",
    "text": "What is Technical Debt? We use the word frequently, yet we lack a consistent definition. Without a common understanding, it’s challenging to talk about technical debt, especially with those who don’t come from a software engineering background.\nMany equate technical debt to the age of software. It’s true that older codebases can carry a lot, but I’ve also seen technical debt creep in from day one. During my time at AWS, I inherited a team that had built up significant technical debt, causing a serious impact on velocity - and this was a 6-month-old team!\nI’ve found one of the best ways of explaining technical debt is to first understand how we accrue it. In this article, I’ll cover several ways I’ve seen organizations build up technical debt: moving too quickly, customer pivots, departing engineers, new engineers, lack of technical direction, technical decay, and a fragile development environment.\nFor each, I’ll share how this technical debt occurs, the impact it may have on your own team, and strategies for addressing it."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nFor startups, I don’t believe the answer is to slow down and try to do things perfectly the first time. While it sounds good in theory, I’ve never been part of an organization that has figured out the definitive architecture on day one.\nI’ve found a better approach is to acknowledge you will accrue technical debt, and set up the right mechanisms for paying it back in the future. These include documenting shortcuts (as they are being taken) and protecting engineering time in future sprints to address them.\nFor organizations already dealing with entanglement in their codebase, an effective strategy can be to paint a vision of disentanglement with your team.\nAt Code.org, we are going through this very process as we disentangle two core parts of our monolith: a Rails app (used by our students and teachers) and a Sinatra app (used for content and marketing materials) that have many cross dependencies with each other.\nWhile we can deploy both successfully, separating the two will bring many advantages. This includes the ability to ship content updates outside of the deploy window and a far smaller repo size - as well as putting us on a path to further decouple other components in each application.\nRather than try to disentangle everything in one go, we are finding it more effective to break the work into milestones, with each milestone offering either value for students or teachers - or increasing developer productivity."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-1",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-1",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nFor many startups, especially ones that go through many pivots, this is a common growing pain, but one that can be mitigated against.\nIn the previous example, instead of copy/pasting code, we should have created a separate customer service with separate data from day one - and then treated this as the most valuable single source of truth. This would have avoided the pain of unpicking complex user details from a monolith in the future.\nFor existing organizations who suffer with this type of technical debt today, one approach is to create an additional abstraction layer, move client calls across, and deprecate the old code and model. At Concur, we successfully used this approach to move customers across to a new generation of our expense product.\nWhat we learned, however, is not to expect an overnight success story - these projects are complex, often multi-year, especially for large codebases - however when completed successfully, can help unlock a lot of the technical debt accrued from multiple early pivots."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-2",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-2",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nWe can’t stop people from leaving, but when an engineer announces their intention to move on, I try to over-index on setting up in-person knowledge transfer with the team.\nThis should not be just an hour in their last week. It should be most, if not all, of the engineer’s remaining time with the organization. This investment is critical for other engineers to build their own mental models of the system, even it means that feature work has to stop for a sprint or two.\nIn addition, following a key engineer’s departure, I’ve found it’s critical to encourage a culture of accepting failure over paralysis. As long as the right boundaries are in place, I always prefer the conversation of “we tried this, but it broke things and we need to revert” vs. “we are too scared to make the change.”"
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-3",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-3",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nIt starts with the interview. I’ve found I either need to hire engineers with prior experience of our stack (which can increase the hiring timeline) or be very deliberate in sharing the details of the stack they will work on. If they have a background in a different technology, I try to set the expectation there will be no opportunity for a rewrite in the near term and gauge their curiosity about learning what we have.\nWhen the new engineer starts, I believe it’s important to evangelize our current tech stack. “Yes, it has issues, but this got us to where we are today!” I share articles and news about the ecosystem (even older stacks have vibrant developer communities) and, if they come up, quickly shut down any conversations about rewriting.\nFinally, it’s important to invest in developer education. As an example, at Code.org we offer an annual professional development stipend that can an engineer can use for conferences, online courses, and other training materials. We’ve found these all can help newer engineers close their knowledge gap with a new platform."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-4",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-4",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nA document outlining current and future technical direction is essential. The document doesn’t need to go into an intricate deep level of detail - but it should provide the right guardrails, while continuing to support a level of autonomy for the team.\nThe architectural tenets doc we have at Code.org lists attempts to do this using eight tenets - ranging from standardizing on a well-structured monorepo (vs. creating multiple repos) through to guidelines for storing new data and creating new APIs. If you don’t have a document similar to this, it can be an enlightening exercise to pull together a working group (a cross section of engineers on the team) to create one.\nIt’s one thing to have a nice document. It’s another to go implement the required changes, especially if there are already inconsistencies in the codebase. Custom linters can help. These linters can run on each commit and report on the state of the system. For example, “45 out of 90 components are implemented as old classes.” Each commit can still go through, but the linter serves as a visible and persistent reminder to the team.\nThese types of linters can also prevent future regressions. At Code.org, we’ve recently implemented a linter that reports on any new connections between two monolithic parts of the application we are decoupling."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-5",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-5",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nStart by cataloguing the current versions of all components and their EOL dates. This will give you a prioritized list of the ones you should upgrade first.\nAs we’ve been undertaking many upgrades at Code.org, we’ve discovered that when you are several versions out of date, it’s prudent to consider multiple minor version upgrades vs. one major jump. For example, we needed to upgrade our version of Ruby from 2.5.0 to 3.0.5. We found it was more manageable to go from 2.5 to 2.7.5 to 3.0 and then to 3.0.5 rather than trying to upgrade everything in one go.\nDuring each of these upgrades, we were also keen to define what success meant. For us, this included 100% of the code switched to using the new version of the library and a full cleanup (removal) of old dependencies. Again, linters helped a lot with this.\nFor dependencies used across multiple development teams, it’s effective to block out sprints where all teams come together to work on the upgrade. (At Code.org, we call these summer swarms and typically run these when we have periods of downtime during the academic year.)\nFinally, for more complex upgrades such as languages or operating systems, it’s worth considering assigning engineers on a full-time basis. While it might be painful to slow down feature work, many engineers will often view it as a welcomed challenge, especially given the positive impact for the overall team."
  },
  {
    "objectID": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-6",
    "href": "p/how-we-accrue-technical-debt/index.html#how-can-we-address-this-6",
    "title": "How We Accrue Technical Debt",
    "section": "How can we address this?",
    "text": "How can we address this?\nA first step is to increase the focus on developer tooling.\nIn many of my prior teams - and at Code.org - we’ve set up a developer working group, where a subgroup of engineers document and cost out their frustrations with the current tooling. The costing part is critical, as time spent on supporting a fragile environment is often unaccounted for in traditional product planning.\nOut of this should come a sense of what to prioritize. This often starts as standardization across hardware and software, but can expand into how an organization can produce a 100% scriptable development environment. At Code.org, we still have work ahead of us to enable this, but once this is done, it should open up the opportunity of bringing on volunteer engineers from outside the organization.\nContainerization can help with scripting a new development environment. Many IDEs now support Development Containers, an open specification for using Docker-based containers as full development environments. At Code.org, we are learning it can take effort to move the team to a containerized environment. However, this can pave the way for expanded use cases, such as cloud-based IDEs and expanding the use of containers to our staging and production environments."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "",
    "text": "I was sad to learn of Niklaus Wirth’s death on New Year’s Day. In college, I used Modula-2, Pascal, and Delphi, and my love of coding may have been very different without Wirth’s contributions. May he rest in peace.\nAs I was reminiscing about languages and tools I used to use, I recalled how much time I spent in the debugger. I was always using the debugger. It was the primary tool to learn new code, understand why my code wasn’t working, and ultimately figure out how to fix it.\nWhen I speak to developers today, however, especially those earlier in their career, using a debugger seems to be a lost art.\nAs an example, I was recently working with one of our developers, helping diagnose why their build was taking so long. I couldn’t help but notice they were sprinkling console.log() statements throughout their code to figure out whether a line had been reached and the value of a variable in scope.\nWhen I asked, “Why don’t you use the debugger?” there were several reasons. Some were valid, others were myths, and many were related to their setup, but all had turned this engineer off the idea.\nAnd this developer is not alone. In a recent thread on Hacker News titled, “Why are we not using debuggers more?”, I found it fascinating to see the polarization of opinions in the comments.\nIn this article, I’ll expand on this and cover several reasons developers may not be using the debugger. I’ll then share the benefits of using a debugger I’ve seen in my teams and explore the potential connection between debugging and generative AI."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#inspections-and-evaluations",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#inspections-and-evaluations",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Inspections and evaluations",
    "text": "Inspections and evaluations\nAs you probably know, debuggers enable you to inspect the value of any variable when a breakpoint is reached.\nFor example, in this computer vision application, I can use the debugger to inspect the value of the delegate, image, and model variables when the detectObjects function is called.\n\n\n\nScreenshot of the variables pane in VS Code Debugger\n\n\nMany IDEs also support “inline views”, where the editor displays the values of variables in scope alongside each line of code. This can be useful for quickly seeing simple values at runtime, although you still need the inspector for complex objects.\nFinally, most IDEs also support the evaluation of expressions at runtime. This can help support a more complex inspection or to view the output from a function.\n\nWhy is this better than console.log?\nFirst, you don’t have to write any console.log statements! (And then remove them, especially after you’ve pushed your commit!)\nMore importantly, not only does a debugger show the values of variables at runtime, but it also provides the context of what else is in scope.\nOn many occasions, I’ve used a debugger and discovered a value or method that was available in a module or class - one that I hadn’t realized existed: “Wow! I didn’t realize the cv object contains the list of devices - now I don’t need to pass them separately.”"
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#dynamic-breakpoints",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#dynamic-breakpoints",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Dynamic breakpoints",
    "text": "Dynamic breakpoints\nAs well as breakpoints that stop when the line of code is reached, debuggers also support dynamic breakpoints. These include “break on exception”, which will pause the debugger if an uncaught exception is raised, and conditional breakpoints.\nUsing a conditional breakpoint, the debugger stops only when an expression evaluates to true.\n\n\n\nA conditional breakpoint in VS Code Debugger\n\n\nFor example, let’s imagine I was experiencing an issue when my computer vision model was running on the CPU instead of the GPU. Using a conditional breakpoint, the debugger only breaks when the passed delegate variable is set to “CPU”. This enables me to ignore all the other times that the GPU was being used.\n\nWhy is this better than console.log?\nBreaking on exception is very efficient - way more so than just logging the exception to stdout. The debugger pauses and provides all the context needed to diagnose the issue.\nThe alternative - using console.log - requires finding the exception in the logs, tracing which line caused it, inserting a console.log to write some additional values, and re-running your program (likely many times over).\nConditional breakpoints are equally productive, especially for edge cases. You can use these breakpoints to trap known values, such as the delegate variable in the last example, and unexpected ones - for example, stopping when a passed object is null/undefined."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#walking-the-call-stack",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#walking-the-call-stack",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Walking the call stack",
    "text": "Walking the call stack\nWhen a debugger hits a breakpoint, besides variables, you have access to the call stack. The call stack is the sequence of calls that was made between starting the program and the current line of code being executed.\n\n\n\nThe call stack window in VS Code Debugger\n\n\nAs shown above, in our computer vision example, the debugger has paused on a breakpoint. It’s now easy to trace the call stack - all the way from the user clicking the run button (the onclick function at the bottom of the stack) through to the detectObjects method being called in the cv library.\n\nWhy is this better than console.log?\nNot only does the call stack give you visibility you wouldn’t get with a console.log statement, but it can be really useful for learning unfamiliar code.\nEspecially when I’ve run a project for the first time, the call stack provides insight into the dependencies between parts of the system. Over time, this helps me create a mental model of how everything fits together: “Oh wow, I didn’t realize that module x got called by module y.”"
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#setting-values",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#setting-values",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Setting values",
    "text": "Setting values\nDebuggers allow you to inspect values, but you may not know that you can set values at runtime as well. This is one of my favorite features, as you can change a value and often reduce the time to see the impact.\n\n\n\nSetting variables in VS Code Debugger\n\n\nIn the above example, I can right click on the delegate variable, manually set the value to ‘CPU’. After continuing execution, this will force the model to run on the CPU.\n\nWhy is this better than console.log?\nI’ve often used this for a couple of scenarios. The first is to test error conditions and handling. For example, imagine a user has reported that the page crashes if they try to create an account with a username longer than 16 characters. It’s trivial to set a breakpoint, set the value of username to something longer than 16 characters, and then step through to diagnose the offending code.\nI’ve also used this approach to jump quickly to other parts of the application. For example, set a manual breakpoint, change the value of level to 20, and resume the debugger."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#integrating-with-ai-coding-assistants",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#integrating-with-ai-coding-assistants",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Integrating with AI coding assistants",
    "text": "Integrating with AI coding assistants\nYou may have used an AI coding assistant (e.g., GitHub Copilot) to help with generating code. I believe that integrating coding assistants with the debugger will take this one step further.\nAs we’ve seen in previous sections, when a debugger reaches a breakpoint, it has a lot of context about the running application. This includes the current code being executed, all the variables in scope, any exceptions, and the call stack.\nThis context is incredibly useful if sent to an LLM. In the case of an unhandled exception, the exception and all the context leading up to the exception can be fed to the LLM. This is a lot more powerful than just copying and pasting a generic exception message into ChatGPT.\nI believe we’ll see more advanced use cases of the debugging context working hand-in-hand with an LLM. These may include providing other optimizations, such as recommending shorter call paths or eliminating redundancies.\nThis is a nascent area, with some of this functionality taking shape in the early adopter builds of GitHub Copilot. If you’d like to find out more, I recommend watching Session BRK231H from Microsoft’s Ignite conference in 2023. Fast forward to the 25 minute mark, where Mark Downie shows a development version of Copilot chat working alongside the debugger to diagnose an unhandled exception in his C# code."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#get-your-environment-working",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#get-your-environment-working",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Get your environment working",
    "text": "Get your environment working\nMost importantly, I recommend setting aside time to set up your own development environment to support debugging. This may involve installing some additional libraries or tools - for example, installing the debug gem in a Ruby environment. To enable debugging for JavaScript and TypeScript environments, you will also need to generate source maps in your build process.\nI’ve also found it useful to get into the habit of configuring my IDE to run the debugger by default. (To do this, you can create a single debug configuration - or, if that’s not possible, replace your keyboard shortcut for running the project to debugging instead).\nBy doing this, you’ll always have access to the debugger at runtime. When things aren’t working, it’s then easy to set a breakpoint and inspect the code vs. having to adjust your thinking to restarting the application with a debugger attached. (And if you are worried that your program will always be stopping, most IDEs support a “mute all breakpoints” option.)\nOne additional side effect is if you do set the debugger as the default target, you’ll likely dispel the myth that debugging is slow on today’s modern machines."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#become-a-evangelist-for-using-the-debugger-in-your-own-team",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#become-a-evangelist-for-using-the-debugger-in-your-own-team",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Become a evangelist for using the debugger in your own team",
    "text": "Become a evangelist for using the debugger in your own team\nOnce you have your environment working, one of our principal engineers at Code.org recommends becoming an evangelist in your own team. As he puts it, “don’t just enable the debugger for yourself, enable it for your teammates.”\nThis can be as simple as sharing, committing, and maintaining the IDE configuration harnesses that enable one-click debugging for your project."
  },
  {
    "objectID": "p/is-using-a-debugger-becoming-a-lost/index.html#explore-remote-debugging",
    "href": "p/is-using-a-debugger-becoming-a-lost/index.html#explore-remote-debugging",
    "title": "Is Using a Debugger Becoming a Lost Art?",
    "section": "Explore remote debugging",
    "text": "Explore remote debugging\nAs you master your own development environment, I’ve encouraged my teams to go on and understand how remote debugging works, especially for those working on distributed applications.\nThis involves understanding the protocols behind remote debugging, such as GDB Remote Serial Protocol, Chrome DevTools Protocol, and Java Debug Wire Protocol, among others.\nIf you are interested in diving deeper here, I’d recommend Practical Debugging at Scale [Almog], especially if you are running Java-based applications on Kubernetes."
  },
  {
    "objectID": "p/shared-keyboard-shortcuts-on-macos/index.html",
    "href": "p/shared-keyboard-shortcuts-on-macos/index.html",
    "title": "Shared Keyboard Shortcuts on macOS and Linux",
    "section": "",
    "text": "I often switch between Mac and Linux for development. The Mac is my go-to machine for my main applications and development specific to the Apple ecosystem. On a separate PC running Ubuntu, I work on several other repos and anything else required for x86 development.\nSwitching between the two can be challenging, especially when trying to remember keyboard shortcuts. Many issues stem from both machines having physically different keyboard layouts, but there are also nuances with different applications. For example, to open a new terminal window on the Mac, the default shortcut is Command-T (using iTerm2). On Linux, in Gnome-Terminal, it’s Ctrl-Shift-T. Even when remapping Command and Ctrl keys around on one of the machines, it’s still a different operation.\nAfter spending far too long to try to solve this, I’ve come up with three techniques I’ve found helped.\n\nOwn Your Shortcut Keys\nEarlier in my career, I found it easy to quickly memorize new sets of shortcut keys. For example, I could install a new IDE and adjust to using SHIFT-F5 to launch the debugger instead of Ctrl-Shift-R.\nMaybe it’s a case of getting older, but that’s become more difficult - or more accurately, I’ve become more stuck in my ways about wanting to dictate the shortcut keys I want to use vs. having applications set them for me. Plus, no one shares keyboards any more (unless you are an advocate of in-person pair programming), so no one should care if I have a wacky set of keyboard shortcuts as long as I can remember them.\nMy first recommendation therefore is to own your shortcut keys. Think about what keyboard shortcut feels most natural to you for each action, and let that drive how you setup your system. For reference, maintain a table of your shortcut keys. Here’s mine.\n\n\nConsistent Modifier Keys\nModifier keys (these are the keys that modify others like Ctrl, Shift, Alt, etc.) are different between Mac and PCs, and many PC keyboards also have variations. On my Mac, the layout of the modifier keys (to the left of the space bar) is as follows:\nFn - Ctrl - Opt - Cmd\nYet, on my DELL, the layout is:\nCtrl - Fn - Win - Alt\nEven if the keyboard shortcuts are identical between the machines, I find myself having to frequent look down at the keyboard to reorient to the layout.\nI’ve found the solution to this is to not to. Instead of following the keys on the keyboard, I have a mental model of how modifier keys should operate across all keyboards.\nFor me, I always expect the Meta key (Command or Windows key) to be immediately to the left of the space bar. The key directly to the left of the Meta is always Alt/Option. If there are four modifier keys, the key to its left is always Fn. Finally, the key is the bottom left is always Ctrl. Again, this is my muscle memory of what I’ve learned over the many years - yours may be completely different.\nWith my mental model for this keyboard layout, I then ignore the labels printed on the keys and use tools to map them equivalently.\nOn the Mac, you can use the Modifier Keys option in the Keyboard system preferences to swap these if needed. In Linux, you can do something similar using TweakUI in Gnome, or setxkbmap.\n(Note: If you need to swap the Fn and Ctrl keys on a PC, many times this has to be done via a Bios setting as Fn is not recognized as a standard key interrupt.)\n\n\nRemapping the Rest\nWith a uniform set of modifier keys, you can now start to remap the other keys. On Linux, there are many different options:\nxmodmap: This works well if you want to swap out a single key for another single key, but doesn’t do much more than that. It won’t handle chords (e.g., mapping Win-T to Ctrl-T) or other complex operations.\nxbindkeys: Typically, xbindkeys is used in combination with xvkbd or xdotool. xbindkeys traps the interrupt for a keypress or chord, and then xvkbd or xdotool simulates an alternative keypress. While on the surface it looks nice, I’ve had issues when trying to implement it. First, it is slow. It worked for remapping a single key, but not suitable for multiple keypresses in succession. Second, it seems inconsistent. This may have been how I was using the --clearmodifiers flag in xdotool, but I found that one in every ten chords wouldn’t map correctly. Finally, both xvkbd and xdotool use the testing API in X, which is deprecated in Wayland.\nxkeysnail: This is the tool that has worked the best for me. xkeysnail is a python script that captures input from /dev/input/eventXX devices, remaps them, and redirects it to /dev/uinput. It supports chords, complex operations (e.g., pressing a key and having a sequence of keys played back), and performs really well. It also has the added feature of mapping keys specific to the window in focus (using the WM_CLASS in Gnome). Therefore, Ctrl-Shift-T can be mapped to a different replacement keyboard shortcut in Gnome Terminal vs. VS Code. Here is an example of my setup.\nxkeysnail does have a couple of downsides, however. Because it acts as a new virtual keyboard device, it overrides any existing modmaps that have been previously applied. This makes it a little more difficult to set different combinations for different keyboards attached to the same machine. Finally, xkeysnail must run as root (for writing to /dev/uinput), which makes it a little more work to get running as a startup process.\nFinally, as your keyboards may be assigned different /dev/input/eventXX devices on reboot/reconnection, you’ll need to pass the correct device to xkeysnail. I’ve written a script that does this automatically."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html",
    "href": "p/technical-debt-repayment-plans/index.html",
    "title": "Technical Debt Repayment Plans",
    "section": "",
    "text": "Like many organizations, Code.org has its fair share of technical debt. At the beginning of last school year, we agreed to dedicate 20% of engineering time towards reducing it. While we had good intentions, we didn’t do a stellar job of managing the time. Engineers would approach me asking me whether we had spent the 20% and if not, whether they could they use some of it.\nFor this school year, we brainstormed different allocation models - which I fondly call repayment plans, analogous to a plan you might put together to reduce credit card debt. We came up with five options, all designed to distribute our 20% allocation of engineering time in various ways.\nIn this article, I’ll share an overview of these repayment plans, together with advantages and disadvantages of each. As we were developing these, we realized that there is no perfect option and, as we’ll uncover, some repayment plans work better for some types of technical debt over others."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#advantages",
    "href": "p/technical-debt-repayment-plans/index.html#advantages",
    "title": "Technical Debt Repayment Plans",
    "section": "Advantages",
    "text": "Advantages\nThis can be a good plan for bugs and issues that engineers can fix and ship in a few hours (or less than two days). For example, I’ve seen this work well for small accessibility tasks (i.e., adding alt text across many components)."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#disadvantages",
    "href": "p/technical-debt-repayment-plans/index.html#disadvantages",
    "title": "Technical Debt Repayment Plans",
    "section": "Disadvantages",
    "text": "Disadvantages\nThis plan is challenging for tech debt tasks that take more than a couple of days. For long-running tasks, engineers face a context switch and ramp-up time each sprint.\nIt can also be difficult to work on tech debt items that span different teams. Engineers in multiple teams need to align on the day (or days) in the sprint that they are working on tech debt.\nIf the allocation of days is at the end of the week or sprint, there is a risk of feature work eating into the allocation. “I just need a few more hours to get this feature completed before I start work on that technical debt…”"
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#advantages-1",
    "href": "p/technical-debt-repayment-plans/index.html#advantages-1",
    "title": "Technical Debt Repayment Plans",
    "section": "Advantages",
    "text": "Advantages\nThis can be a good plan for longer product cycles - e.g., shipping every few months or a quarter. (In a recent podcast, I learned the VS Code team does something similar, allocating the last week before their monthly release.)\nEngineers can work on larger tasks. A two-week sprint offers a lot more time to pick up larger tasks vs. two days, as per the previous plan.\nAll engineers are working on tech debt reduction items at the same time. This makes it easier to tackle technical debt that has cross-team dependencies (such as upgrading a library that multiple teams use).\nThis plan can also give product owners a dedicated sprint for planning before the next four-sprints worth of feature work."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#disadvantages-1",
    "href": "p/technical-debt-repayment-plans/index.html#disadvantages-1",
    "title": "Technical Debt Repayment Plans",
    "section": "Disadvantages",
    "text": "Disadvantages\nSimilar to the previous plan, feature work can eat into the allocation if not completed. “We just need a few more days to get this feature completed before we can start our technical debt sprint…”\nTwo weeks may still not be enough for many tech debt reduction tasks. For example, migrating your application to use a different storage engine may be difficult in a two-week window.\nThis repayment plan offers a lot of engineering time condensed into a small amount of calendar time. For example, an engineering team size of 50 equates to 4,000 hours of engineering time in a 2-week sprint. To use this effectively requires planning and coordination before the sprint starts. Otherwise, there is a real risk of engineers starting the sprint, not knowing what they should work on first."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#advantages-2",
    "href": "p/technical-debt-repayment-plans/index.html#advantages-2",
    "title": "Technical Debt Repayment Plans",
    "section": "Advantages",
    "text": "Advantages\nCompared to the previous two, this plan is more effective for tech debt reduction work that requires multiple engineers working together for more than a sprint.\nThis increased amount of time to work on technical debt also reduces the number of context switches for engineers.\nThis plan also provides wider visibility for how tech debt reduction fits with the product roadmap. (Tech debt reduction becomes a conversation during product planning, which can only be a good thing.)"
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#disadvantages-2",
    "href": "p/technical-debt-repayment-plans/index.html#disadvantages-2",
    "title": "Technical Debt Repayment Plans",
    "section": "Disadvantages",
    "text": "Disadvantages\nThe flexible time boundaries can cause tension between product features and tech debt reduction work. While both are important, product features will often index higher on urgency. For example, “We are getting pressure from our customers to bring feature X forward. Can we push out the tech debt reduction work by a few sprints?”\nTech debt reduction items in the calendar still have an end date. Because of this, engineers need to estimate the work to ensure it fits into the allotted calendar time.\nIn larger organizations, the product calendar may not align across multiple teams. This can make it challenging to work on tech debt reduction items that affect other teams. For example, if one team is trying to remove tech debt in the same area of the codebase that another is working in to ship a new feature."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#advantages-3",
    "href": "p/technical-debt-repayment-plans/index.html#advantages-3",
    "title": "Technical Debt Repayment Plans",
    "section": "Advantages",
    "text": "Advantages\nThis plan works well for organizations that have seasonal usage. For example, at Code.org, we’ve run these swarms during the summer when students are typically not in school (and our usage is lower). This makes it easier to have planned downtime, if required.\nAll engineers are working on tech debt reduction together, which makes cross-team dependencies easier to manage.\nEngineers get a longer time to work on items. For example, 20% of a 50-week working calendar equates to 10 weeks (or five 2-week sprints). For many organizations, this is a lot of time to make inroads on several large technical debt items.\nHaving run these before, I’ve observed a lot of positive energy from these longer durations of allocated time (vs. spending 2 days per sprint). It also provides the opportunity for a large retro and celebration at the end of the 10 weeks."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#disadvantages-3",
    "href": "p/technical-debt-repayment-plans/index.html#disadvantages-3",
    "title": "Technical Debt Repayment Plans",
    "section": "Disadvantages",
    "text": "Disadvantages\n10 weeks is a long time to not ship any features! This may be especially hard to bite off in startup environments.\nSomewhat related, what do product owners (or any other members of the team who might not be directly working on technical debt) work on during this time?\nWhile 10 weeks allows for large upgrades or refactors of the code base, there is always a chance that these don’t get completed in time. If this happens, the next opportunity to work on these might not be until the following year, which can leave a lot of work in a dangling state until then."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#advantages-4",
    "href": "p/technical-debt-repayment-plans/index.html#advantages-4",
    "title": "Technical Debt Repayment Plans",
    "section": "Advantages",
    "text": "Advantages\nThis plan can offer focus to a group of engineers passionate about reducing technical debt for their organization. The team can also operate autonomously, managing their own backlog of technical debt items, and changing priorities as needed.\nAs this is a full-time team, the engineers don’t have to estimate the work or try to fit it into a calendar. They just start the work!\nRelated, there is also less pressure for the team to complete the work by a certain date, compared to all the prior plans."
  },
  {
    "objectID": "p/technical-debt-repayment-plans/index.html#disadvantages-4",
    "href": "p/technical-debt-repayment-plans/index.html#disadvantages-4",
    "title": "Technical Debt Repayment Plans",
    "section": "Disadvantages",
    "text": "Disadvantages\nFinding enough engineers who want to work on tech debt reduction (vs. product features) can be challenging. It’s often tricky to create a process where engineers can volunteer for this new team without feeling pressure from their manager or having concerns about their promotion path or resume.\nIn smaller organizations, a dedicated team may not have the right experience for all the technical debt work. For example, a dedicated tech debt team comprising primarily web engineers could find it more difficult to refactor a database or server-side logic - slowing down the work or requiring additional time from engineers outside of the team.\nAs with the “aligned with product calendar” plan, trying to reduce technical debt while another team is trying to ship a new feature can be challenging."
  },
  {
    "objectID": "p/what-shape-is-your-engineering-team/index.html",
    "href": "p/what-shape-is-your-engineering-team/index.html",
    "title": "What Shape Is Your Engineering Team?",
    "section": "",
    "text": "When I meet an engineering team for the first time, I’m always intrigued to learn the “shape” of the team.\nWhat do I mean by “shape”? Well, if you map the ratios of engineers across all levels in the team, you can often derive a shape from it.\nFor example, imagine a team of engineers that range from SDE-1 (entry level) to SDE-5 (principal). Let’s say the team has 15 engineers and comprises five SDE-1s, four SDE-2s, three SDE-3s, two SDE-4s, and one SDE-5.\nIf we draw a shape depicting the number of engineers at each level, we end up with a triangle:\n\n\n\nA “Triangle-Shaped” Team\n\n\nUnderstanding the shape of a team can offer a lot of insight. First, it provides data for hiring decisions. For example, do you need another senior engineer and if so, how will this impact the balance of the team?\nIt can also help identify mentoring opportunities by looking at the ratio of junior engineers to senior engineers who can provide guidance.\nFinally, it can help highlight gaps and help understand the impact upcoming promotions or changes in levels may have.\nThere is no perfect shape to aspire to. Instead, I’ve found certain shapes of teams work well for different environments, various sizes of teams, and the type of product you are developing.\nIn this article, I’ll introduce fives shapes of teams I commonly come across: The triangle, the inverted triangle, the diamond, the rectangle, and hourglass.\nFor each, I’ll describe the structure of the team, the environment and products I’ve found this shape can best work for, and a few things to watch out for along the way.\n\nThe Triangle\nAs we covered this in the introduction, let’s start with the triangle.\n\n\n\nA “Triangle-Shaped” Team\n\n\nThe triangle has a larger ratio of junior engineers compared to senior engineers. I’ve seen this shape (and inherited many teams of this shape) at Microsoft, SAP, and Amazon, all of whom invest heavily in college recruiting and internship programs. This investment provides a strong pipeline of SDE-1 engineers.\nI’ve found triangle-shaped teams work for well-established products, often those that have a good balance of new feature development and existing bug fixing and operational load. With a higher ratio earlier in their career, these teams often have engineers eager to learn new skills and take on responsibilities.\nThis spread also offers mentoring opportunities with senior developers responsible for the architecture and technical direction. At AWS, one of my senior engineers would often hold weekly “learn the architecture” sessions with small groups of our recent college graduates.\nWhat to watch for: While these teams can be effective, if you have a team of this shape, I recommend monitoring the workload of the one or two senior or principal engineers at the top of the triangle.\nOften, these engineers will be responsible for the architectural decisions and technical direction for new features. This, combined with what may be a heavy mentoring workload, can sometimes lead to burnout.\n\n\nThe Inverted Triangle\nAs the name implies, the inverted triangle is the opposite, with a larger ratio of principal and senior engineers compared to mid-level and junior engineers.\n\n\n\nAn “Inverted Triangle-Shaped” Team\n\n\nI’ve found an inverted triangle team can be very effective in early-stage startups and for new product development.\nAt Amazon, I had the opportunity to build a team from scratch, responsible for developing a v1 hardware device. I optimized towards hiring a higher ratio of principal and senior engineers who came with hardware, firmware, software, and machine learning backgrounds.\nThis seniority of the team provided the years of experience we needed to get the product designed and developed - something that would have been more challenging with a more traditional triangle-shaped team.\nWhat to watch for: While I always learn from teams of this shape - the experience of the team often provides new angles I’m not thinking about - they can come with a couple of things to watch for.\nFirst, given the seniority of many engineers in the team, it’s common to have many strong (and sometimes conflicting) opinions, especially when debating a new design or direction. With my team at Amazon, I recall having to step in often to help the team move forward with a technical decision.\nSecond, the work has to be new and engaging for engineers who bring this level of experience. Without this, there may not be enough “senior-level” work to go around, which can lead to boredom and eventual attrition.\nFinally, while inverted triangles work well for new product development, as the product matures and needs to take on more support and maintenance tasks, there will be a need to fill out the rest of the triangle to create more balance.\n\n\nThe Diamond\nThe diamond is a larger ratio of mid-level engineers compared to senior and junior levels. The larger the ratio of mid-level engineers, the wider the diamond.\n\n\n\nA “Diamond-Shaped” Team\n\n\nA few of my teams, including the engineering org when I first joined Code.org, have been diamond-shaped. Often, teams develop into a diamond when an organization has had a very active college recruitment program in past years and those engineers go through a couple of promotion cycles.\nDiamond-shaped teams can also be very effective for well-established products. The higher ratio of mid-level engineers brings the experience and understanding of the nuances of the system.\nWhat to watch for: If you have a diamond-shaped team, I recommend looking at the width of the diamond. If it’s too wide, there can be a high number of mid-level engineers looking for complex projects to stretch their abilities - and potentially not enough projects available to go around.\nA wide diamond can also have the same effect for mentoring opportunities - with a larger number of mid-level engineers looking to mentor a smaller number of junior engineers. (This, however, is often easier to mitigate with interns, contractors, and other peer mentoring opportunities.)\n\n\nThe Rectangle\nA rectangular-shaped team has roughly equal ratios across each level.\n\n\n\nA “Rectangular-Shaped” Team\n\n\nWhile I’ve found many large tech companies favor triangular-shaped teams, I’ve often come across rectangle-shaped teams in small and mid-sized organizations. Many of our engineering teams at Code.org are good examples.\nDepending on the size of the engineering organization, it can also be common to see a rectangle-shaped organization and then different shapes for each of the sub-teams.\nFor established products, rectangles offer a good balance of feature development suitable for engineers at all levels. The equal ratio can also provide steady mentoring opportunities and career pathways.\nWhat to watch for: While the rectangle offers plenty of mentoring opportunities, it’s important to balance college recruiting and interns - as too much can push the team towards a triangle and too less can lead to fewer mentoring opportunities for mid-level engineers.\n\n\nThe Hourglass\nAn hourglass-shaped team is the inverse of the diamond, with a larger number of senior and junior engineers compared to mid-level. Some hourglass-shaped teams may not even have any mid-level engineers. (I call these “air-gapped.”)\n\n\n\nAn “Hourglass-Shaped” Team\n\n\nDuring my career, I’ve only come across one or two instances. Often, the hourglass shape forms when an inverted triangle team pivots to hiring college graduates (often because of slowing feature development). I’ve also seen this shape form during periods of high attrition or when two or more teams merge.\nWhat to watch for: I don’t recommend optimizing towards an hourglass-shaped team, as in extreme cases, it can create a disconnect between the senior and junior engineers on the same team.\nThis can impact technical decision making, where senior engineers make all decisions and don’t involve the rest of the team. This shape can also introduce mentoring challenges, especially if senior engineers prefer to mentor mid-level vs. early career engineers.\nThe combination of the above can lead to senior engineers feeling frustrated that other engineers are not contributing - and less experienced engineers also becoming frustrated they are not getting the support they need from the rest of the team.\nOn the occasions I’ve come across this shape, I’ve always used future hiring opportunities to fill out the middle.\n\n\nConclusion\nIn this article, I’ve shared the concept of identifying the shape of your team and five common shapes I’ve come across: the triangle, the inverted triangle, the diamond, the rectangle, and hourglass.\nWhile there are likely many other shapes, I hope this approach has offered a unique perspective for identifying the ratios in your own teams and thinking about your future hiring.\nI’d love to hear more about the shapes you have in your teams and what you find as advantages and disadvantages of each."
  },
  {
    "objectID": "p/why-dont-software-developers-practice-051/index.html",
    "href": "p/why-dont-software-developers-practice-051/index.html",
    "title": "Why Don’t Software Developers Practice?",
    "section": "",
    "text": "Many professions incorporate practice into their daily routines. Athletes wake up early to practice regularly. Successful musicians often have a strict routine of practice. And many artists will dedicate time to practicing new techniques they then incorporate into their work.\nYet, as software developers, we don’t embrace this concept. We often expect developers to perform (i.e., ship software) 100% of their working time. Imagine if this happened with the other professions. Athletes would run races non-stop, musicians would spend all their time performing in front of an audience, and artists would need to produce masterpiece after masterpiece without fail.\nThis is concerning. Always being under pressure to perform adds significant psychological stress. Having no room for practice means no room for failure, even if a company’s values claims otherwise. No time for practice also means no time for experimentation, or more accurately, experimentation happens in production. Can you imagine a musician trying a new instrument for the first time in front of a packed concert hall?\nThe concept of practice holds so much potential for improving software development. Practice can help developers try something new - maybe it’s a new language, framework, or tool. Practice can also help developers experiment - such as trying different techniques to cache data or an alternate way to get user input. Practice can also help build muscle memory - increasing the ability to write code without constantly relying on Stack Overflow.\nWhat does it take to incorporate practice into software development? There are many angles, but here are five steps I’ve found useful with my teams to develop a culture of practice:\n\nDefine Your Goal\nThe first step is to define a goal. As a developer, what do you want to achieve from practice? Your goal should be bold and should even feel a little intimidating just to say it aloud. It shouldn’t be too bold that it’s never achievable - but it shouldn’t be something you can quickly accomplish in a couple of days either.\nTo give an example, I recently wanted to learn the Web Audio API. I had no experience with doing anything audio-related in the browser, and given the size of the spec, it was intimidating at first glance. It did, however, provide for a good goal for which to focus my practice time.\n\n\nOne Step at a Time\nAfter establishing a goal, it’s important to work the first step on the journey. The key is not to figure out everything at once - you’ll likely end up spending more time deconstructing the tasks vs. actually spending time in practice - just the next step in order to make progress.\nGoing back to my example of learning Web Audio, I decided the first step was to work out how to play a simple WAV file in the browser. That was the sole focus of my first practice session, and it was easy to know when I had accomplished it. After completing this, to figure out what I should do in my next practice session, I went back to the Web Audio spec and figured out that creating a simple oscillator would be a good next step.\nIt’s important to define one step at a time, and not to over-commit. Even though the goal may be intimidating, practice shouldn’t be a stretch. If it is, it will become stressful and you’ll likely give up. I like to set a goal of 50%: If I have 90 minutes to practice, my next step should feel about 45 minutes’ worth of work, providing a healthy buffer as I figure things out. Plus, if I end early and accomplish something, I feel much better than running out of time, having over-committed.\n\n\nCreate a Feedback Loop\nFeedback is critical for practice. Not only does it provide a sense of accomplishment, but you need to know when things are working and if you are making progress.\nIn their book, Peak: Secrets from the New Science of Expertise, Ericsson and Pool define two types of practice: Purposeful practice and deliberate practice.\nPurposeful practice is exploratory. It’s done on your own and you create your own feedback loops. Figuring out how to play a WAV file is an example of purposeful practice. If my code plays the sound correctly, that’s successful feedback.\nDeliberate practice involves another person, such as a coach or mentor. For athletes, this could be a track coach offering advice on improving posture. For software developers, this could be a mentor or a more senior developer offering feedback on the effectiveness of the code.\nAs you set up your own practice, decide which type of feedback loop is going to be more useful for you. With the abundance of samples and tutorials in our profession, you’ll likely default to purposeful practice, but don’t discount the value of deliberate practice, especially if there is an opportunity to learn from others.\n\n\nSchedule Time to Practice\nMany developers I speak with like the idea of practice, but struggle with fitting it into the calendar. Scheduling time is one of the most important parts of setting up a routine of practice.\nPractice should always be outside of a “performance window”. Imagine a musician who has two concerts, one in the morning and one in the afternoon. They will probably be tired in between, so practice then is likely counter-productive. The same is true for software development. Carving out an hour in between sprint tasks in the middle of the day may not be the most effective time.\nInstead, look for windows of time outside of your “performances”. For me, this is early mornings. I don’t know why, but I find it much easier to switch into a mode of practice before taking on any other work. As a result, I try to be steadfast about reserving early morning hours for practice time.\nThis, of course, begets the question: Should practice time be taken out of the hours allocated to a sprint? If practice time can be scheduled this way, sure, but I lean towards practice being about true personal development, and therefore dedicating time outside of working hours. This approach also opens up the ability to practice things that are not related to your day job. Maybe you want to learn about Rust, but your company has no plans to adopt it. It’s easier to commit to this if your practice window is on your own time.\n\n\nCreate an Environment for Focus\nAfter scheduling time on the calendar, it can be too easy to adopt a mindset that this is “free time” vs. “practice time”.\nYou should treat practice time as you would any other time where you need to focus. Turn off notifications and close windows with anything that could be a distraction. It can be effective to create a new virtual desktop and then dedicate that desktop entirely to the practice activity. This can help create a separate space, free of clutter, without going through the pain of closing or minimizing my other work.\nI’ve also found the Pomodoro Technique works well for practice. I find that I can sustain practice for about 90 minutes before I need to take a break or resume other activities. Having a timer helps me frame and dedicate the time to do this.\n\n\nTreat Creations as Impermanent\nWater art, popular in Buddhism, is the concept of painting using water. As the artist paints, the creation comes to life, but as the water slowly evaporates, the art disappears, returning to a clean board.\nPractice should have a similar impermanence. The goal of practice is about learning. There’s no need to publish, share, create tests, create a prototype, or do anything production-worthy with code created during practice. If you want to save your work in between practice sessions, create a private repo, but resist trying to turn the output into something bigger.\nInstead, focus on the learning experience. I guarantee that there will be a time where you’ll apply what you’ve learned. Wait for that time to come vs. trying to force a creation out of your practice session.\n\n\nConclusion\nI hope you find the five steps in this article useful, and start incorporating the concept of practice into software development. If we do, I suspect it will be a net positive for our profession, making for more productive and happy developers."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Creating a Document-Driven Culture\n\n\n\nTechnical Leadership\n\nWriting\n\n\n\nAmazon is famous for banning PowerPoint in favor of written documents. But why and how does this work? I share my experience and ideas for creating a document-driven culture.\n\n\n\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould CTOs Write Code?\n\n\n\nTechnical Leadership\n\n\n\nIn this article, I dust off this age-old question and answer it using an action logic framework.\n\n\n\n\n\n\nFeb 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Using a Debugger Becoming a Lost Art?\n\n\n\nIDEs\n\nDebugging\n\nGenerative AI\n\n\n\nWhy this is happening, how we can bring it back, and where generative AI may help.\n\n\n\n\n\n\nFeb 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Shape Is Your Engineering Team?\n\n\n\nTechnical Leadership\n\n\n\nUse the shape of your team to help with product fit, hiring decisions, and mentoring opportunities.\n\n\n\n\n\n\nJan 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechnical Debt Repayment Plans\n\n\n\nTechnical Debt\n\n\n\nIntroducing the concept of ‘repayment plans’ for reducing technical debt in your organization.\n\n\n\n\n\n\nJan 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow We Accrue Technical Debt\n\n\n\nTechnical Debt\n\n\n\nIn this article, I cover the different ways that organizations accrue technical debt, the impact that this has, and strategies for tackling it.\n\n\n\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nShared Keyboard Shortcuts on macOS and Linux\n\n\n\nmacOS\n\nLinux\n\n\n\nCreating consistent keyboard shortcuts that work well between the two.\n\n\n\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Better Technical Documents\n\n\n\nTechnical Leadership\n\nWriting\n\n\n\nFive techniques that have helped me write better technical documents.\n\n\n\n\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Don’t Software Developers Practice?\n\n\n\nTechnical Leadership\n\n\n\nCould practice help us develop new skills, experiment, and build muscle memory?\n\n\n\n\n\n\nDec 22, 2023\n\n\n\n\n\n\nNo matching items"
  }
]